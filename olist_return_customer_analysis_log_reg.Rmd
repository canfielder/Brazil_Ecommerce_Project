---
title: "Brazilian Ecommerce - EDA"
author: "Evan Canfield"
date: "3/15/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Import
## Libraries
```{r}
if (!require(pacman)) {install.packages('pacman')} 
p_load(
  broom,
  car,
  caTools,
  DMwR,
  geosphere, 
  ggcorrplot,
  janitor, 
  lubridate, 
  Hmisc,
  pROC,
  purrr,
  ROSE,
  skimr, 
  tidyverse,
  questionr
)

set.seed(5590)
```

## Data
```{r}
# Olist Dataset
df_cust <- read.csv(file = "data/olist_customers_dataset.csv", stringsAsFactors = FALSE)
#df_geo_loc <- read.csv(file = "data/olist_geolocation_dataset.csv", stringsAsFactors = FALSE)
df_order_items <- read.csv(file = "data/olist_order_items_dataset.csv", stringsAsFactors = FALSE)
#df_order_pay <- read.csv(file = "data/olist_order_payments_dataset.csv", stringsAsFactors = FALSE)
#df_order_review <- read.csv(file = "data/olist_order_reviews_dataset.csv", stringsAsFactors = FALSE)
df_orders <- read.csv(file = "data/olist_orders_dataset.csv", stringsAsFactors = FALSE)
#df_products <- read.csv(file = "data/olist_products_dataset.csv", stringsAsFactors = FALSE)
#df_sellers <- read.csv(file = "data/olist_sellers_dataset.csv", stringsAsFactors = FALSE)
#df_translation <- read.csv(file = "data/product_category_name_translation.csv", stringsAsFactors = FALSE)

# Brazillian Population Data
#df_brazil_pop <- read.csv(file = "data/population_estimates_dou_2019.csv", stringsAsFactors = FALSE)

# Processed Data
df_cust_processed <- readRDS(file = "data/customer_processed.rds")
```

### Clean Names
The following function converts column names to snake case so there is a consistent look to all the column names.
```{r}
clean_names_func <- function(df){
  df <- df %>% clean_names(case = "snake")
  return (df)
}

df_cust <- clean_names_func(df_cust)
#df_geo_loc <- clean_names_func(df_geo_loc)
df_order_items <- clean_names_func(df_order_items)
#df_order_pay <- clean_names_func(df_order_pay)
#df_order_review <- clean_names_func(df_order_review)
df_orders <- clean_names_func(df_orders)
#df_products <- clean_names_func(df_products)
#df_sellers <- clean_names_func(df_sellers)
#df_translation <- clean_names_func(df_translation)
#df_brazil_pop <- clean_names_func(df_brazil_pop)
```

# General Analysis of Return Customers
# Percent Totals
This section generates some general data on return customers.

First, we need to determine how many unique customers there are, as a reference. 
```{r}
df_cust_return %>% select(customer_unique_id) %>% distinct() %>% nrow()
```

First we want to see what percentage of customers are return.
```{r}
df_cust_return_list <- df_cust %>% 
  add_count(customer_unique_id) %>% 
  rename(return = n) %>% 
  mutate(return = if_else(return > 1, 1, 0),
       return = as.factor(return)) %>% 
  select(customer_unique_id, return) %>% 
  distinct()

as.data.frame(table(df_cust_return_list$return))

x = 2997/(2997+93099)
x
```

Now we also want to see the sales breakdown between return and non-return customers.
```{r}
df_order_items %>% 
  group_by(order_id) %>% 
  summarise(sales = sum(price)) %>% 
  ungroup() %>% 
  left_join(df_orders %>% select(order_id, customer_id), by = "order_id") %>% 
  left_join(df_cust %>% select(customer_id, customer_unique_id),
            by = "customer_id") %>% 
  left_join(df_cust_return_list, by = "customer_unique_id") %>% 
  group_by(return) %>% 
  summarise(sales_total = sum(sales)) %>% 
  ungroup() %>% 
  mutate(percent_sales = round(100 * sales_total/sum(sales_total),1))
```

Finally, lets look at the total number of items sold based on return or non-return.
```{r}
df_order_items %>% 
  left_join(df_orders %>% select(order_id, customer_id),
            by = "order_id") %>% 
  left_join(df_cust %>% select(customer_id, customer_unique_id),  
            by = "customer_id") %>% 
  left_join(df_cust_return_list, by = "customer_unique_id") %>% 
  select(order_id, return) %>% 
  group_by(return) %>% 
  count() %>% 
  rename(total_items = n) %>% 
  ungroup() %>% 
  mutate(percent_items = round(100 * total_items/sum(total_items),1))
```

# Logistic Regression Modeling
We'll define the dataframe for input into the model.
```{r}
df <- df_cust_processed
```

## Prepare Data
Verify repeat customer split is as expected. 
```{r}
as.data.frame(table(df$return))
```
Also, due to the large number of customers who only have made a single purchase, the review score variable still functions like a discrete, 5 value scale. So, instead of using the average, well round the values and convert to factor.
```{r}
df <- df %>% 
  mutate(review_score_mean = round(review_score_mean,0),
         review_score_mean = as.factor(review_score_mean)) %>% 
  rename(review_score = review_score_mean)

#df %>% glimpse()
```


We need to drop the id variables for the final modeling.
We will also drop mis to accept because I don't think this variable means anything.
```{r}
df <- df %>% 
  select(-customer_unique_id,
         -freight_value_mean,
         -mins_to_accept_mean)
```

We also want to relevel the Product Category and the Payment Type categories.
```{r}
df$product_category <- factor( df$product_category , ordered = FALSE )
df$product_category <- relevel(x = df$product_category, ref = "health_beauty")

df$payment_type <- factor( df$payment_type , ordered = FALSE )
df$payment_type  <- relevel(x = df$payment_type , ref = "credit_card")
```

We will also need to drop three product categories: security, flowers, and party supplies. These categories have only one return customer. So, when we split the training and test data, that will leave some of the data without a positive target variable. Hence, when we use Random Over Sampling, this generates outliers. These categories are a very small part of the data (194 observations), so we will drop them.
```{r}
drop_category_list <- c("flowers", "party_supplies", "security", "christmas_supplies")

df <- df %>% 
  filter(!(product_category %in% drop_category_list))
```


## Split Data 
For evaluation purposes we'll need to split the data.
```{r}
sample = sample.split(df$return, SplitRatio = 0.75)
df_train_initial = subset(df, sample == TRUE)
df_test  = subset(df, sample == FALSE)
```

### Balance Data
Because the return variable is greatly unbalanced, we will synthetically balance the data. For this problem I will used the ROSE (Random Over Sampling) method.
```{r}
df_train <- df_train_initial

# Pre Rose Balancing
as.data.frame(table(df_train$return))


#rose_dataset_size <- df_train %>% nrow() * 2
rose_dataset_size <- df_train %>% nrow() * 1
```

```{r}
df_train_rose <- ROSE(return ~ ., data = df_train,
     N = rose_dataset_size, 
     p = 0.5)$data

# Post Rose Balancing
as.data.frame(table(df_train_rose$return))
```

## Model 1 - Standard
### Run Model
```{r}
model <- glm(formula = return ~ .,
                  family = binomial(link = "logit"),
                  data = df_train)
```

```{r}
glance(model)
```

```{r}
summary(model)
```

```{r}
tidy(x = model, 
     exponentiate = TRUE)
```


### Extract Model Data
```{r}
 # Extract Model Data and Add index as a Column, And Shuffle
# Define Model Data
model.data <- augment(model) 

# Shuffle - For Residual Plot
model.data <- model.data[sample(nrow(model.data)),]

# Add Index
model.data <- model.data %>%   mutate(index = 1:n()) 
```

### Test Assumptionss
#### Linearity
Generate Probabilities - Training Set
```{r}
probabilities <- predict(model, type = "response")
predicted_classes <- ifelse(probabilities > 0.5, "pos", "neg")
```

The dataset is very large. We will testa sample data.
##### Standard Distribution
```{r warning=FALSE}
predictors <- df %>%  keep(is_numeric) %>%   names()

# Add Logit to Dataframe
df_train_logit <- df_train %>%
  mutate(logit = log(probabilities/(1-probabilities))) 


df_train_logit %>%
  keep(is.numeric) %>%
  sample_frac(size = 0.05) %>% 
  gather(key = "predictors", value = "predictor_value", -logit) %>% 
  ggplot(aes(logit, predictor_value)) +
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") +
  theme_bw() +
  facet_wrap(~predictors, scales = "free_y")
```

#### Outliers - Cooks Distance
The following is the Cooks Distance plot. The ROSE oversmapling has added so many "outliers" that it does not seem like they are outliers any more. No filtering will be perfomed based on Cooks Distance.
```{r}
plot(model, which = 4, id.n = 5)
```

#### Residuals
```{r}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = return), alpha = .5) +
  theme_bw()
```

#### Create Outlier List > 3 Std Dev
There are no values greater than three standard deviations.
```{r}
std_dev_3_data <- model.data %>% 
  filter(abs(.std.resid) > 3)

outlier_index_list <- std_dev_3_data$index
outlier_index_list
```
#### ROC
```{r}
test_prob <- predict(model, newdata = df_test, type = "response")

roc_curve <- roc(df_test$return ~ test_prob, plot = TRUE, print.auc = TRUE)
```

## Model 2 - Over Sampled
### Run Model
```{r}
model <- glm(formula = return ~ .,
                  family = binomial(link = "logit"),
                  data = df_train_rose)
```

```{r}
glance(model)
```

```{r}
#summary(model)
```

### Extract Model Data
```{r}
 # Extract Model Data and Add index as a Column, And Shuffle
# Define Model Data
model.data <- augment(model) 

# Shuffle - For Residual Plot
model.data <- model.data[sample(nrow(model.data)),]

# Add Index
model.data <- model.data %>%   mutate(index = 1:n()) 
```

### Test Assumptionss
#### Linearity
Generate Probabilities - Training Set
```{r}
probabilities <- predict(model, type = "response")
predicted_classes <- ifelse(probabilities > 0.5, "pos", "neg")
```

The dataset is very large. We will testa sample data.
```{r}
predictors <- df %>%  keep(is_numeric) %>%   names()

# Add Logit to Dataframe
df_train_rose_logit <- df_train_rose %>%
  mutate(logit = log(probabilities/(1-probabilities))) 


df_train_rose_logit %>%
  keep(is.numeric) %>%
  sample_frac(size = 0.05) %>% 
  gather(key = "predictors", value = "predictor_value", -logit) %>% 
  ggplot(aes(logit, predictor_value)) +
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") +
  theme_bw() +
  facet_wrap(~predictors, scales = "free_y")
```


#### Outliers - Cooks Distance
The following is the Cooks Distance plot. The ROSE oversmapling has added so many "outliers" that it does not seem like they are outliers any more. No filtering will be perfomed based on Cooks Distance.
```{r}
plot(model, which = 4, id.n = 5)
```

#### Residuals
```{r}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = return), alpha = .5) +
  theme_bw()
```

#### Create Outlier List > 3 Std Dev
There are no values greater than three standard deviations.
```{r}
std_dev_3_data <- model.data %>% 
  filter(abs(.std.resid) > 3)

outlier_index_list <- std_dev_3_data$index
outlier_index_list
```
#### ROC
```{r}
test_prob <- predict(model, newdata = df_test, type = "response")

roc_curve <- roc(df_test$return ~ test_prob, plot = TRUE, print.auc = TRUE)
```

# Log Transformations
We will try log transforming each numeric variable.
```{r}
df_log <- df %>% 
  mutate_if(is.numeric, list(log = log)) %>% 
  select(-c(price_mean, days_to_deliver_mean, dist_km_mean))

#df_log %>% glimpse()
```


## Split Data 
For evaluation purposes we'll need to split the data.
```{r}
sample = sample.split(df_log$return, SplitRatio = 0.75)
df_train_log = subset(df, sample == TRUE)
df_test_log  = subset(df, sample == FALSE)
```

### Balance Data
Because the return variable is greatly unbalanced, we will synthetically balance the data. For this problem I will used the ROSE (Random Over Sampling) method.
```{r}
# Pre Rose Balancing
as.data.frame(table(df_train_log$return))
```

```{r}
df_train_log_rose <- ROSE(return ~ ., data = df_train_log,
     N = rose_dataset_size, 
     p = 0.5)$data

# Post Rose Balancing
as.data.frame(table(df_train_log_rose$return))
```

## Model 3 - Log Transformed
### Run Model
```{r}
model <- glm(formula = return ~ .,
                  family = binomial(link = "logit"),
                  data = df_train_log_rose)
```

```{r}
glance(model)
```

```{r}
summary(model)
```

```{r}
odds_ratio <- tidy(x = model, 
     #conf.int = TRUE, 
     #conf.level = 0.95,
     exponentiate = TRUE) %>% 
  mutate(estimate = round(estimate, 3),
         p.value = signif(p.value, digits = 3),
         significant = if_else(p.value <= 0.05, 1, 0)) %>% 
  select(term, estimate, p.value, significant)

odds_ratio
```


#### Odds Ratio With Confidence Interval
```{r}
odds_ratio_w_conf <- tidy(x = model, 
     conf.int = TRUE, 
     conf.level = 0.95,
     exponentiate = TRUE) %>% 
  mutate(estimate = round(estimate, 3),
         p.value = signif(p.value, digits = 3),
         significant = if_else(p.value <= 0.05, 1, 0))

odds_ratio_w_conf
```


### Extract Model Data
```{r}
 # Extract Model Data and Add index as a Column, And Shuffle
# Define Model Data
model.data <- augment(model) 

# Shuffle - For Residual Plot
model.data <- model.data[sample(nrow(model.data)),]

# Add Index
model.data <- model.data %>%   mutate(index = 1:n()) 
```

### Test Assumptionss
#### Linearity
Generate Probabilities - Training Set
```{r}
probabilities <- predict(model, type = "response")
predicted_classes <- ifelse(probabilities > 0.5, "pos", "neg")
```

The dataset is very large. We will testa sample data.
```{r}
predictors <- df %>%  keep(is_numeric) %>%   names()

# Add Logit to Dataframe
df_train_rose_logit <- df_train_rose %>%
  mutate(logit = log(probabilities/(1-probabilities))) 


df_train_rose_logit %>%
  keep(is.numeric) %>%
  sample_frac(size = 0.05) %>% 
  gather(key = "predictors", value = "predictor_value", -logit) %>% 
  ggplot(aes(logit, predictor_value)) +
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") +
  theme_bw() +
  facet_wrap(~predictors, scales = "free_y")
```


#### Outliers - Cooks Distance
The following is the Cooks Distance plot. The ROSE oversmapling has added so many "outliers" that it does not seem like they are outliers any more. No filtering will be perfomed based on Cooks Distance.
```{r}
plot(model, which = 4, id.n = 5)
```

#### Residuals
```{r}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = return), alpha = .5) +
  theme_bw()
```

#### Create Outlier List > 3 Std Dev
There are no values greater than three standard deviations.
```{r}
std_dev_3_data <- model.data %>% 
  filter(abs(.std.resid) > 3)

outlier_index_list <- std_dev_3_data$index
outlier_index_list
```
#### ROC
```{r}
test_prob <- predict(model, newdata = df_test, type = "response")

roc_curve <- roc(df_test$return ~ test_prob, plot = TRUE, print.auc = TRUE)
```


